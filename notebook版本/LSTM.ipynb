{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lml/loader.py:64: UserWarning: Deprecated! since version 0.0.3. Please use scan_plugins_regex!\n",
      "  \"Deprecated! since version 0.0.3. Please use scan_plugins_regex!\"\n",
      "pyecharts_snapshot is abscent or cannot be imported\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lml/utils.py\", line 42, in do_import\n",
      "    return _do_import(plugin_module_name)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lml/utils.py\", line 51, in _do_import\n",
      "    plugin_module = __import__(plugin_module_name)\n",
      "ModuleNotFoundError: No module named 'pyecharts_snapshot'\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import tqdm\n",
    "import warnings\n",
    "from pyecharts import Bar , Timeline\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn, rnn\n",
    "from tensorflow.contrib import learn as tflearn\n",
    "from tensorflow.contrib.learn import SKCompat\n",
    "from tensorflow.python.framework import dtypes\n",
    "from pyecharts import Bar , Timeline\n",
    "import requests\n",
    "import math\n",
    "import time\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import re\n",
    "PI = math.pi\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"count_df.csv\", encoding='gbk')\n",
    "df = df.sort_values(by = ['刷卡站点','月份', '日' , '时', '第x个五分钟'])\n",
    "df = df.query(\"月份 == 9\")\n",
    "\n",
    "hours = []\n",
    "minuteOfHours = []\n",
    "for hour in range(24):\n",
    "    for minuteOfHour in range(12):\n",
    "        hours.append(hour)\n",
    "        minuteOfHours.append(minuteOfHour)\n",
    "        \n",
    "test_df = pd.DataFrame({\"时\": hours , \"第x个五分钟\": minuteOfHours })\n",
    "# df = pd.merge(df , test_df,  how = 'outer', on = ['时', '第x个五分钟'])\n",
    "\n",
    "stations = set(df['刷卡站点'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for station in tqdm.tqdm(stations):\n",
    "    mask = df['刷卡站点'] == station\n",
    "    temp_df = df[mask]\n",
    "    whole_df = pd.DataFrame({\"时\": hours , \"第x个五分钟\": minuteOfHours })\n",
    "    temp_df = pd.merge(temp_df ,whole_df , on = ['时', '第x个五分钟'] , how = 'outer' )\n",
    "    temp_df = temp_df.fillna(0)\n",
    "    temp_df = temp_df.sort_values(by = ['时', '第x个五分钟'])\n",
    "    temp_df = temp_df[['时', '第x个五分钟', '进出站状态']]\n",
    "    temp_df.columns = ['时','第x个五分钟', '客流量' ]\n",
    "    temp_df.to_csv(\"./data/{}.csv\".format(station), index = None , encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能函数\n",
    "### StandardSclaer_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardSclaer_training(X, y):\n",
    "    X_mean, y_mean = X.mean(axis=0), y.mean(axis=0)\n",
    "    X_std, y_std = X.std(axis=0), y.std(axis=0)\n",
    "    ss_X = (X - X_mean) / X_std\n",
    "    ss_y = (y - y_mean) / y_std\n",
    "    params = {\"X_mean\": X_mean,\n",
    "              \"X_std\": X_std,\n",
    "              \"y_mean\": y_mean,\n",
    "              \"y_std\": y_std}\n",
    "    return ss_X, ss_y,params\n",
    "\n",
    "# ss_train_X, ss_train_y, train_params = StandardSclaer_training(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardSclaer_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardSclaer_testing(X,y, params ):\n",
    "    X_mean = params['X_mean']\n",
    "    X_std = params['X_std']\n",
    "    y_mean = params['y_mean']\n",
    "    y_std = params['y_std']\n",
    "    ss_X = (X - X_mean) / X_std\n",
    "    ss_y = (y - y_mean) / y_std\n",
    "    return ss_X, ss_y\n",
    "\n",
    "# ss_test_X, ss_test_y = StandardSclaer_testing(test_X, test_y, train_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reversal_StandardSclaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reversal_StandardSclaer(ss_X, ss_y, params):\n",
    "    X_mean = params['X_mean']\n",
    "    X_std = params['X_std']\n",
    "    y_mean = params['y_mean'][0]\n",
    "    y_std = params['y_std'][0]\n",
    "    X = ss_X * X_std + X_mean\n",
    "    y = ss_y * y_std + y_mean\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_rnn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_data(data, time_step, is_label = False):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data = data)\n",
    "    rnn_df = []\n",
    "    n = len(data)\n",
    "    for i in range(n - time_step):\n",
    "        if is_label:\n",
    "            item = data.iloc[i + time_step].as_matrix()\n",
    "        else:\n",
    "            item = data.iloc[i : i + time_step].as_matrix()\n",
    "        \n",
    "        rnn_df.append(item)\n",
    "    return np.array(rnn_df, dtype=np.float32)\n",
    "\n",
    "# ss_train_X = get_rnn_data(ss_train_X, time_step=7, is_label=False)\n",
    "# ss_train_y = get_rnn_data(ss_train_y, time_step=7, is_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(time_steps, \n",
    "               rnn_layers, \n",
    "               dense_layers=None, \n",
    "               learning_rate=0.01, \n",
    "               optimizer='Adam',\n",
    "               learning_rate_decay_fn = None): # [Ftrl, Adam, Adagrad, Momentum, SGD, RMSProp]\n",
    "    print(time_steps)\n",
    "    #exit(0)\n",
    "    \"\"\"\n",
    "        Creates a deep model based on:\n",
    "            * stacked lstm cells\n",
    "            * an optional dense layers\n",
    "        :param num_units: the size of the cells.\n",
    "        :param rnn_layers: list of int or dict\n",
    "                             * list of int: the steps used to instantiate the `BasicLSTMCell` cell\n",
    "                             * list of dict: [{steps: int, keep_prob: int}, ...]\n",
    "        :param dense_layers: list of nodes for each layer\n",
    "        :return: the model definition\n",
    "        \"\"\"\n",
    "\n",
    "    def lstm_cells(layers):\n",
    "        print('-------------------------sdsdsdsdssd---------------------------------------------',layers)\n",
    "        if isinstance(layers[0], dict):\n",
    "            for layer in layers:\n",
    "                cells = []\n",
    "                if layer.get('keep_prob'):\n",
    "                    cell = rnn.DropoutWrapper(rnn.BasicLSTMCell(layer['num_units'],state_is_tuple=True),\n",
    "                                              layer['keep_prob'])\n",
    "                    cells.append(cell)\n",
    "                else:\n",
    "                    cell = rnn.BasicLSTMCell(layer['num_units'], state_is_tuple=True)\n",
    "                    \n",
    "                cells.append(cell)\n",
    "            return cells\n",
    "        else:\n",
    "            return [rnn.BasicLSTMCell(steps, state_is_tuple=True) for steps in layers]\n",
    "        \n",
    "#             return [rnn.DropoutWrapper(rnn.BasicLSTMCell(layer['num_units'],state_is_tuple=True),layer['keep_prob'])\n",
    "#                     if layer.get('keep_prob')\n",
    "#                     else rnn.BasicLSTMCell(layer['num_units'], state_is_tuple=True)\n",
    "#                     for layer in layers]\n",
    "\n",
    "#         return [rnn.BasicLSTMCell(steps, state_is_tuple=True) for steps in layers]\n",
    "\n",
    "    def dnn_layers(input_layers, layers):\n",
    "        if layers and isinstance(layers, dict):\n",
    "            return tflayers.stack(input_layers, tflayers.fully_connected,\n",
    "                                  layers['layers'],\n",
    "                                  activation=layers.get('activation'),\n",
    "                                  dropout=layers.get('dropout'))\n",
    "        elif layers:\n",
    "            return tflayers.stack(input_layers, tflayers.fully_connected, layers)\n",
    "        else:\n",
    "            return input_layers\n",
    "\n",
    "    def _lstm_model(X, y):\n",
    "        stacked_lstm = rnn.MultiRNNCell(lstm_cells(rnn_layers), state_is_tuple=True)\n",
    "        x_ =  tf.unstack(X, num=time_steps, axis=1)\n",
    "\n",
    "\n",
    "        output, layers = rnn.static_rnn(stacked_lstm, x_, dtype=dtypes.float32)\n",
    "        output = dnn_layers(output[-1], dense_layers)\n",
    "        prediction, loss = tflearn.models.linear_regression(output, y)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss, tf.contrib.framework.get_global_step(), optimizer=optimizer,\n",
    "            learning_rate = tf.train.exponential_decay(learning_rate, \n",
    "                                                       tf.contrib.framework.get_global_step(), \n",
    "                                                       decay_steps = 1000, \n",
    "                                                       decay_rate = 0.9, \n",
    "                                                       staircase=False, \n",
    "                                                       name=None))\n",
    "        print('learning_rate',learning_rate)\n",
    "        return prediction, loss, train_op\n",
    "\n",
    "    # https://www.tensorflow.org/versions/r0.10/api_docs/python/train/decaying_the_learning_rate\n",
    "\n",
    "    return _lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 6\n",
    "RNN_LAYERS = [{'num_units': 50},\n",
    "             {'num_units': 10}]\n",
    "DENSE_LAYERS = None\n",
    "LEARNINGRATE = 0.001\n",
    "optimizer = 'Adam'\n",
    "TRAINING_STEPS = 500\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络+预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "fileNames = os.listdir(\"/Users/apricity/AnacondaProjects/job/地铁预测/LSTM_output/\")\n",
    "s = {fileName.split('.')[0] for fileName in fileNames }\n",
    "\n",
    "for station in tqdm.tqdm(stations - s):\n",
    "    temp_df = pd.read_csv('./data/{}.csv'.format(station), encoding='gbk')\n",
    "    X = get_rnn_data(temp_df['客流量'], time_step = 6, is_label = False)\n",
    "    y = get_rnn_data(temp_df['客流量'], time_step = 6, is_label = True)\n",
    "    ss_train_X, ss_train_y, train_params = StandardSclaer_training(X, y)\n",
    "    \n",
    "    lstm = lstm_model(TIMESTEPS, RNN_LAYERS, DENSE_LAYERS, LEARNINGRATE, optimizer)\n",
    "    validation_monitor = learn.monitors.ValidationMonitor(ss_train_X, ss_train_y,)\n",
    "    regressor = SKCompat(learn.Estimator(lstm))\n",
    "    SKCompat(regressor.fit(ss_train_X, ss_train_y,\n",
    "                  monitors=[validation_monitor],\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  steps=TRAINING_STEPS))\n",
    "    \n",
    "    y_pred = np.array(regressor.predict(ss_train_X), dtype = np.float32)\n",
    "    _, y_pred = reversal_StandardSclaer(ss_train_X, y_pred, train_params)\n",
    "    temp_df['预测客流量'] =  np.concatenate([np.zeros(6) , y_pred])\n",
    "    \n",
    "    temp_df.to_csv('./LSTM_output/{}.csv'.format(station), encoding='gbk', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFs = []\n",
    "for fileName in os.listdir('./LSTM_output/'):\n",
    "    temp_df = pd.read_csv('./LSTM_output/' + fileName , encoding='gbk')\n",
    "    station = fileName.split('.')[0]\n",
    "    temp_df['站点'] = station\n",
    "    DFs.append(temp_df)\n",
    "pred_df = pd.concat(DFs)\n",
    "del DFs\n",
    "\n",
    "def drop_num(station):\n",
    "    re_line_num = re.findall(\"\\d+号线\",station )[0]\n",
    "    n = len(re_line_num)\n",
    "    return station[n:]\n",
    "\n",
    "pred_df['站点'] = pred_df['站点'].apply(drop_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transformlat(coordinates):\n",
    "    lng = coordinates[:, 0] - 105\n",
    "    lat = coordinates[:, 1] - 35\n",
    "    ret = -100 + 2 * lng + 3 * lat + 0.2 * lat * lat + \\\n",
    "        0.1 * lng * lat + 0.2 * np.sqrt(np.fabs(lng))\n",
    "    ret += (20 * np.sin(6 * lng * PI) + 20 *\n",
    "            np.sin(2 * lng * PI)) * 2 / 3\n",
    "    ret += (20 * np.sin(lat * PI) + 40 *\n",
    "            np.sin(lat / 3 * PI)) * 2 / 3\n",
    "    ret += (160 * np.sin(lat / 12 * PI) + 320 *\n",
    "            np.sin(lat * PI / 30.0)) * 2 / 3\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _transformlng(coordinates):\n",
    "    lng = coordinates[:, 0] - 105\n",
    "    lat = coordinates[:, 1] - 35\n",
    "    ret = 300 + lng + 2 * lat + 0.1 * lng * lng + \\\n",
    "        0.1 * lng * lat + 0.1 * np.sqrt(np.fabs(lng))\n",
    "    ret += (20 * np.sin(6 * lng * PI) + 20 *\n",
    "            np.sin(2 * lng * PI)) * 2 / 3\n",
    "    ret += (20 * np.sin(lng * PI) + 40 *\n",
    "            np.sin(lng / 3 * PI)) * 2 / 3\n",
    "    ret += (150 * np.sin(lng / 12 * PI) + 300 *\n",
    "            np.sin(lng / 30 * PI)) * 2 / 3\n",
    "    return ret\n",
    "\n",
    "\n",
    "def gcj02_to_wgs84(coordinates):\n",
    "    \"\"\"\n",
    "    GCJ-02转WGS-84\n",
    "    :param coordinates: GCJ-02坐标系的经度和纬度的numpy数组\n",
    "    :returns: WGS-84坐标系的经度和纬度的numpy数组\n",
    "    \"\"\"\n",
    "    ee = 0.006693421622965943  # 偏心率平方\n",
    "    a = 6378245  # 长半轴\n",
    "    lng = coordinates[:, 0]\n",
    "    lat = coordinates[:, 1]\n",
    "    is_in_china = (lng > 73.66) & (lng < 135.05) & (lat > 3.86) & (lat < 53.55)\n",
    "    _transform = coordinates[is_in_china]  # 只对不在国内的坐标做偏移\n",
    "\n",
    "    dlat = _transformlat(_transform)\n",
    "    dlng = _transformlng(_transform)\n",
    "    radlat = _transform[:, 1] / 180 * PI\n",
    "    magic = np.sin(radlat)\n",
    "    magic = 1 - ee * magic * magic\n",
    "    sqrtmagic = np.sqrt(magic)\n",
    "    dlat = (dlat * 180.0) / ((a * (1 - ee)) / (magic * sqrtmagic) * PI)\n",
    "    dlng = (dlng * 180.0) / (a / sqrtmagic * np.cos(radlat) * PI)\n",
    "    mglat = _transform[:, 1] + dlat\n",
    "    mglng = _transform[:, 0] + dlng\n",
    "    coordinates[is_in_china] = np.array(\n",
    "        [_transform[:, 0] * 2 - mglng, _transform[:, 1] * 2 - mglat]).T\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def bd09_to_gcj02(coordinates):\n",
    "    \"\"\"\n",
    "    BD-09转GCJ-02\n",
    "    :param coordinates: BD-09坐标系的经度和纬度的numpy数组\n",
    "    :returns: GCJ-02坐标系的经度和纬度的numpy数组\n",
    "    \"\"\"\n",
    "    x_pi = PI * 3000 / 180\n",
    "    x = coordinates[:, 0] - 0.0065\n",
    "    y = coordinates[:, 1] - 0.006\n",
    "    z = np.sqrt(x * x + y * y) - 0.00002 * np.sin(y * x_pi)\n",
    "    theta = np.arctan2(y, x) - 0.000003 * np.cos(x * x_pi)\n",
    "    lng = z * np.cos(theta)\n",
    "    lat = z * np.sin(theta)\n",
    "    coordinates = np.array([lng, lat]).T\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def bd09_to_wgs84(coordinates):\n",
    "    \"\"\"\n",
    "    BD-09转WGS-84\n",
    "    :param coordinates: BD-09坐标系的经度和纬度的numpy数组\n",
    "    :returns: WGS-84坐标系的经度和纬度的numpy数组\n",
    "    \"\"\"\n",
    "    return gcj02_to_wgs84(bd09_to_gcj02(coordinates))\n",
    "\n",
    "\n",
    "def mercator_to_bd09(mercator):\n",
    "    \"\"\"\n",
    "    墨卡托转BD-09\n",
    "    :param coordinates: GCJ-02坐标系的经度和纬度的numpy数组\n",
    "    :returns: WGS-84坐标系的经度和纬度的numpy数组\n",
    "    \"\"\"\n",
    "    MCBAND = [12890594.86, 8362377.87, 5591021, 3481989.83, 1678043.12, 0]\n",
    "    MC2LL = [[1.410526172116255e-08, 8.98305509648872e-06, -1.9939833816331, 200.9824383106796, -187.2403703815547,\n",
    "              91.6087516669843, -23.38765649603339, 2.57121317296198, -0.03801003308653, 17337981.2],\n",
    "             [-7.435856389565537e-09, 8.983055097726239e-06, -0.78625201886289, 96.32687599759846, -1.85204757529826,\n",
    "              -59.36935905485877, 47.40033549296737, -16.50741931063887, 2.28786674699375, 10260144.86],\n",
    "             [-3.030883460898826e-08, 8.98305509983578e-06, 0.30071316287616, 59.74293618442277, 7.357984074871,\n",
    "              -25.38371002664745, 13.45380521110908, -3.29883767235584, 0.32710905363475, 6856817.37],\n",
    "             [-1.981981304930552e-08, 8.983055099779535e-06, 0.03278182852591, 40.31678527705744, 0.65659298677277,\n",
    "              -4.44255534477492, 0.85341911805263, 0.12923347998204, -0.04625736007561, 4482777.06],\n",
    "             [3.09191371068437e-09, 8.983055096812155e-06, 6.995724062e-05, 23.10934304144901, -0.00023663490511,\n",
    "              -0.6321817810242, -0.00663494467273, 0.03430082397953, -0.00466043876332, 2555164.4],\n",
    "             [2.890871144776878e-09, 8.983055095805407e-06, -3.068298e-08, 7.47137025468032, -3.53937994e-06,\n",
    "              -0.02145144861037, -1.234426596e-05, 0.00010322952773, -3.23890364e-06, 826088.5]]\n",
    "\n",
    "    x = np.abs(mercator[:, 0])\n",
    "    y = np.abs(mercator[:, 1])\n",
    "    coef = np.array([MC2LL[index] for index in (\n",
    "        np.tile(y.reshape((-1, 1)), (1, 6)) < MCBAND).sum(axis=1)])\n",
    "    return converter(x, y, coef)\n",
    "\n",
    "\n",
    "def converter(x, y, coef):\n",
    "    x_temp = coef[:, 0] + coef[:, 1] * np.abs(x)\n",
    "    x_n = np.abs(y) / coef[:, 9]\n",
    "    y_temp = coef[:, 2] + coef[:, 3] * x_n + coef[:, 4] * x_n ** 2 + coef[:, 5] * x_n ** 3 + coef[:,\n",
    "                                                                                                  6] * x_n ** 4 + coef[:,\n",
    "                                                                                                                       7] * x_n ** 5 + coef[\n",
    "        :,\n",
    "        8] * x_n ** 6\n",
    "    x[x < 0] = -1\n",
    "    x[x >= 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    y[y >= 0] = 1\n",
    "    x_temp *= x\n",
    "    y_temp *= y\n",
    "    coordinates = np.array([x_temp, y_temp]).T\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = \"pk.eyJ1IjoibHVrYXNtYXJ0aW5lbGxpIiwiYSI6Im\\\n",
    "Npem85dmhwazAyajIyd284dGxhN2VxYnYifQ.HQCmyhEXZUTz3S98FMrVAQ\"\n",
    "\n",
    "layout = go.Layout(autosize=True,\n",
    "                   hovermode='closest',\n",
    "                   mapbox=dict(\n",
    "                       accesstoken=mapbox_access_token,\n",
    "                       bearing=0,\n",
    "                       center=dict( lat=31.234941, lon=121.47824),\n",
    "                       pitch=0,\n",
    "                       zoom=10 ),\n",
    "                   )\n",
    "\n",
    "null = None  # 将json中的null定义为None\n",
    "city_code = 289  # 上海的城市编号\n",
    "station_info = requests.get('http://map.baidu.com/?qt=bsi&c=%s&t=%s' % (city_code, int(time.time() * 1000)))\n",
    "station_info_json = eval(station_info.content)  # 将json字符串转为python对象\n",
    "\n",
    "with open(\"station_info_json.json\", 'w') as fr:\n",
    "    json.dump(station_info_json, fr)\n",
    "    \n",
    "with open(\"station_info_json.json\", 'r') as fr:\n",
    "    station_info_json = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color = ('blue', 'green', 'yellow', 'purple', 'orange', 'red', 'violet',\n",
    "#              'navy', 'crimson', 'cyan', 'magenta', 'maroon', 'peru', 'pink')  # 可按需增加\n",
    "\n",
    "# data = []  # 绘制数据\n",
    "# marked = set()\n",
    "# cnt = 0\n",
    "# for line in station_info_json['content']:\n",
    "#     uid = line['line_uid']\n",
    "#     if uid in marked:  # 由于线路包括了来回两个方向，需要排除已绘制线路的反向线路\n",
    "#         continue\n",
    "#     plots = []  # 站台墨卡托坐标\n",
    "#     plots_name = []  # 站台名称\n",
    "#     for plot in line['stops']:\n",
    "#         plots.append([plot['x'], plot['y']])\n",
    "#         plots_name.append(plot['name'])\n",
    "#     plot_mercator = np.array(plots)\n",
    "#     plot_coordinates = bd09_to_wgs84(mercator_to_bd09(plot_mercator))  # 站台经纬度\n",
    "    \n",
    "# #     re_line_num = re.findall(\"\\d+号线\",line['line_name'] )\n",
    "# #     if len(re_line_num) == 1:\n",
    "# #         line_name = re_line_num[0]\n",
    "# #     else:\n",
    "# #         line_name = ''\n",
    "        \n",
    "#     plots_size = []\n",
    "#     for name in plots_name:\n",
    "#         mask = (pred_df[\"站点\"] == name) & (pred_df[\"时\"] == 7) & (pred_df[\"第x个五分钟\"] == 0)\n",
    "#         try:\n",
    "#             flow = pred_df[mask]['预测客流量'].values[0]\n",
    "#         except:\n",
    "#             flow = 0.1\n",
    "#         plots_size.append(flow / 10)\n",
    "# #     print(line['line_name'])\n",
    "\n",
    "#     # 设置标记点的参数\n",
    "#     data.append(\n",
    "#         go.Scattermapbox(\n",
    "#             lon=plot_coordinates[:, 0],  # 站台经度\n",
    "#             lat=plot_coordinates[:, 1],  # 站台纬度\n",
    "#             mode='markers+lines',\n",
    "#             name=line['line_name'],  # 线路名称，显示在图例（legend）上\n",
    "#             text=plots_name,  # 各个点的名称，鼠标悬浮在点上时显示\n",
    "#             # 设置标记点的参数\n",
    "#             marker = go.scattermapbox.Marker( \n",
    "#                 size = plots_size,  # 这个用来控制站点绘制的大小\n",
    "#                 color=color[cnt] ),))\n",
    "#     marked.add(uid)  # 添加已绘制线路的uid\n",
    "#     marked.add(line['pair_line_uid'])  # 添加已绘制线路反向线路的uid\n",
    "#     cnt = (cnt + 1) % len(color)\n",
    "# fig = dict(data=data, layout=layout)\n",
    "# # py.iplot(fig)\n",
    "# py.plot(fig, filename='Shanghai_railway.html')  # 生成html文件并打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fig(hour , minuteOfHour):\n",
    "    color = ('blue', 'green', 'yellow', 'purple', 'orange', 'red', 'violet',\n",
    "                 'navy', 'crimson', 'cyan', 'magenta', 'maroon', 'peru', 'pink')  # 可按需增加\n",
    "\n",
    "    data = []  # 绘制数据\n",
    "    marked = set()\n",
    "    cnt = 0\n",
    "    for line in station_info_json['content']:\n",
    "        uid = line['line_uid']\n",
    "        if uid in marked:  # 由于线路包括了来回两个方向，需要排除已绘制线路的反向线路\n",
    "            continue\n",
    "        plots = []  # 站台墨卡托坐标\n",
    "        plots_name = []  # 站台名称\n",
    "        for plot in line['stops']:\n",
    "            plots.append([plot['x'], plot['y']])\n",
    "            plots_name.append(plot['name'])\n",
    "        plot_mercator = np.array(plots)\n",
    "        plot_coordinates = bd09_to_wgs84(mercator_to_bd09(plot_mercator))  # 站台经纬度\n",
    "\n",
    "        plots_size = []\n",
    "        for name in plots_name:\n",
    "            mask = (pred_df[\"站点\"] == name) & (pred_df[\"时\"] == hour) & (pred_df[\"第x个五分钟\"] == minuteOfHour)\n",
    "            try:\n",
    "                flow = pred_df[mask]['预测客流量'].values[0]\n",
    "            except:\n",
    "                flow = 0.1\n",
    "            plots_size.append(flow / 10)\n",
    "    #     print(line['line_name'])\n",
    "\n",
    "        # 设置标记点的参数\n",
    "        data.append(\n",
    "            go.Scattermapbox(\n",
    "                lon=plot_coordinates[:, 0],  # 站台经度\n",
    "                lat=plot_coordinates[:, 1],  # 站台纬度\n",
    "                mode='markers+lines',\n",
    "                name=line['line_name'],  # 线路名称，显示在图例（legend）上\n",
    "                text=plots_name,  # 各个点的名称，鼠标悬浮在点上时显示\n",
    "                # 设置标记点的参数\n",
    "                marker = go.scattermapbox.Marker( \n",
    "                    size = plots_size,  # 这个用来控制站点绘制的大小\n",
    "                    color=color[cnt] ),))\n",
    "        marked.add(uid)  # 添加已绘制线路的uid\n",
    "        marked.add(line['pair_line_uid'])  # 添加已绘制线路反向线路的uid\n",
    "        cnt = (cnt + 1) % len(color)\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    # py.iplot(fig)\n",
    "    py.plot(fig, filename='Shanghai_{}时_第{}个5分.html'.format(hour , minuteOfHour))  # 生成html文件并打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_fig(7 , 0) # 7时- 0～5分（第0个5分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
